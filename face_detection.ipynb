{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0,\n",
    "  \"metadata\": {\n",
    "    \"colab\": {\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"name\": \"python3\",\n",
    "      \"display_name\": \"Python 3\"\n",
    "    }\n",
    "  },\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"oS98J5s0FaOc\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"\\n\",\n",
    "        \"import imutils #redimencionamento, rotacao\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import cv2 #import OpenCV\\n\",\n",
    "        \"from google.colab.patches import cv2_imshow\\n\",\n",
    "        \"from IPython.display import display, Javascript #webcan leitura\\n\",\n",
    "        \"from google.colab.output import eval_js #webcan leitura\\n\",\n",
    "        \"from base64 import b64decode #biblioteca para codificar dados binários\\n\",\n",
    "        \"\\n\",\n",
    "        \"def take_photo(filename='photo.jpg', quality=0.8):\\n\",\n",
    "        \"  js = Javascript('''\\n\",\n",
    "        \"    async function takePhoto(quality) {\\n\",\n",
    "        \"      const div = document.createElement('div');\\n\",\n",
    "        \"      const capture = document.createElement('button');\\n\",\n",
    "        \"      capture.textContent = 'Capture';\\n\",\n",
    "        \"      div.appendChild(capture);\\n\",\n",
    "        \"\\n\",\n",
    "        \"      const video = document.createElement('video');\\n\",\n",
    "        \"      video.style.display = 'block';\\n\",\n",
    "        \"      const stream = await navigator.mediaDevices.getUserMedia({video: true});\\n\",\n",
    "        \"\\n\",\n",
    "        \"      document.body.appendChild(div);\\n\",\n",
    "        \"      div.appendChild(video);\\n\",\n",
    "        \"      video.srcObject = stream;\\n\",\n",
    "        \"      await video.play();\\n\",\n",
    "        \"\\n\",\n",
    "        \"      // Resize the output to fit the video element.\\n\",\n",
    "        \"      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\\n\",\n",
    "        \"\\n\",\n",
    "        \"      // Wait for Capture to be clicked.\\n\",\n",
    "        \"      await new Promise((resolve) => capture.onclick = resolve);\\n\",\n",
    "        \"\\n\",\n",
    "        \"      const canvas = document.createElement('canvas');\\n\",\n",
    "        \"      canvas.width = video.videoWidth;\\n\",\n",
    "        \"      canvas.height = video.videoHeight;\\n\",\n",
    "        \"      canvas.getContext('2d').drawImage(video, 0, 0);\\n\",\n",
    "        \"      stream.getVideoTracks()[0].stop();\\n\",\n",
    "        \"      div.remove();\\n\",\n",
    "        \"      return canvas.toDataURL('image/jpeg', quality);\\n\",\n",
    "        \"    }\\n\",\n",
    "        \"    ''')\\n\",\n",
    "        \"  display(js)\\n\",\n",
    "        \"  data = eval_js('takePhoto({})'.format(quality))\\n\",\n",
    "        \"  binary = b64decode(data.split(',')[1])\\n\",\n",
    "        \"  with open(filename, 'wb') as f:\\n\",\n",
    "        \"    f.write(binary)\\n\",\n",
    "        \"  return filename\\n\",\n",
    "        \"\\n\",\n",
    "        \"image_file = take_photo()\\n\",\n",
    "        \"\\n\",\n",
    "        \"image = cv2.imread(image_file)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# redimensiona para ter uma largura máxima de 400 pixels\\n\",\n",
    "        \"image = imutils.resize(image, width=400)\\n\",\n",
    "        \"(h, w) = image.shape[:2]\\n\",\n",
    "        \"print(w,h)\\n\",\n",
    "        \"cv2_imshow(image)\\n\",\n",
    "        \"\\n\",\n",
    "        \"!wget -N https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\\n\",\n",
    "        \"!wget -N https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"[INFO] loading model...\\\")\\n\",\n",
    "        \"prototxt = 'deploy.prototxt'\\n\",\n",
    "        \"model = 'res10_300x300_ssd_iter_140000.caffemodel'\\n\",\n",
    "        \"net = cv2.dnn.readNetFromCaffe(prototxt, model)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# redimensiona para ter uma largura máxima de 400 pixels\\n\",\n",
    "        \"image = imutils.resize(image, width=400)\\n\",\n",
    "        \"blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"[INFO] computing object detections...\\\")\\n\",\n",
    "        \"net.setInput(blob)\\n\",\n",
    "        \"detections = net.forward()\\n\",\n",
    "        \"\\n\",\n",
    "        \"for i in range(0, detections.shape[2]):\\n\",\n",
    "        \"\\t# extrair a probabilidade associada à previsão\\n\",\n",
    "        \"\\tconfidence = detections[0, 0, i, 2]\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\t# filtra detecções fracas garantindo que a \\\"confiança\\\" seja\\n\",\n",
    "        \"\\t# maior que o limite mínimo de confiança\\n\",\n",
    "        \"\\tif confidence > 0.5: #Nossa detecção deve ter no mínimo 50% de certeza\\n\",\n",
    "        \"\\t\\t# calcula as coordenadas (x, y) da caixa delimitadora do objeto\\n\",\n",
    "        \"\\t\\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\\n\",\n",
    "        \"\\t\\t(startX, startY, endX, endY) = box.astype(\\\"int\\\")\\n\",\n",
    "        \"\\t\\t# desenha a caixa delimitadora da face junto com a probabilidade associada\\n\",\n",
    "        \"\\t\\ttext = \\\"{:.2f}%\\\".format(confidence * 100)\\n\",\n",
    "        \"\\t\\ty = startY - 10 if startY - 10 > 10 else startY + 10\\n\",\n",
    "        \"\\t\\tcv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\\n\",\n",
    "        \"\\t\\tcv2.putText(image, text, (startX, y),\\n\",\n",
    "        \"\\t\\t  cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\\n\",\n",
    "        \"  \\n\",\n",
    "        \"cv2_imshow(image)\"\n",
    "      ],\n",
    "      \"execution_count\": 1,\n",
    "      \"outputs\": []\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
